import shap
import numpy as np




# 初始化 SHAP 的 TreeExplainer
explainer = shap.TreeExplainer(best_model)

# 计算 SHAP 值
shap_values = explainer.shap_values(X_train)

# 转换 SHAP 值为 numpy.array
# 对于多分类任务，shap_values 是一个列表，每个元素代表一个类别的 SHAP 值
shap_values_numpy = np.array(shap_values)  # 转换为 numpy.array 格式

# 打印 SHAP 值的 shape
print("SHAP values shape:", shap_values_numpy.shape)  # 形状为 (num_classes, num_samples, num_features)

# 提取每个类别的 SHAP 值
shap_values_class_0 = shap_values_numpy[0]  # 类别 0 的 SHAP 值
shap_values_class_1 = shap_values_numpy[1]  # 类别 1 的 SHAP 值
shap_values_class_2 = shap_values_numpy[2]  # 类别 2 的 SHAP 值

# 打印每个类别的 SHAP 值的形状
print("Class 0 SHAP values shape:", shap_values_class_0.shape)  # (num_samples, num_features)
print("Class 1 SHAP values shape:", shap_values_class_1.shape)  # (num_samples, num_features)
print("Class 2 SHAP values shape:", shap_values_class_2.shape)  # (num_samples, num_features)
# 确保 SHAP 值的形状正确
print("shap_values_class_0 shape:", shap_values_class_0.shape)  # 应该是 (num_samples, num_features)
print("X_train.columns shape:", len(X_train.columns))          # 应该是 (num_features,)

# 如果 SHAP 值的形状与 X_train 不一致，需要先切片匹配特征数量
if shap_values_class_0.shape[1] != len(X_train.columns):
    shap_values_class_0 = shap_values_class_0[:, :len(X_train.columns)]
    shap_values_class_1 = shap_values_class_1[:, :len(X_train.columns)]
    shap_values_class_2 = shap_values_class_2[:, :len(X_train.columns)]
# 重新计算每个类别的特征重要性
importance_class_0 = np.abs(shap_values_class_0).mean(axis=0)  # 形状为 (num_features,)
importance_class_1 = np.abs(shap_values_class_1).mean(axis=0)  # 形状为 (num_features,)
importance_class_2 = np.abs(shap_values_class_2).mean(axis=0)  # 形状为 (num_features,)

# 确保形状匹配
print("Importance shapes:", importance_class_0.shape, importance_class_1.shape, importance_class_2.shape)

# 创建一个包含类别特征重要性的 DataFrame
importance_df = pd.DataFrame({
    'Class 0': importance_class_0,
    'Class 1': importance_class_1,
    'Class 2': importance_class_2,
}, index=X_train.columns)

# 根据类别映射表将列名修改为英文描述
type_mapping = {
    0: 'Granulomatous inflammation',  # 异常
    1: 'Benign tumors',     # 正常
    2: 'Non-small cell lung cancer', # 可疑
}

# 修改列名
importance_df.columns = [type_mapping[int(col.split('Class ')[1])] for col in importance_df.columns]
importance_df
# 导入必要的库
import seaborn as sns

# 添加一列用于存储行的和
importance_df['row_sum'] = importance_df.sum(axis=1)

# 按照行和对DataFrame进行排序
sorted_importance_df = importance_df.sort_values(by='row_sum', ascending=True)

# 删除用于排序的行和列
sorted_importance_df = sorted_importance_df.drop(columns=['row_sum'])

elements = sorted_importance_df.index

# 使用 Seaborn 的颜色调色板，设置为 Set2，以获得对比度更高的颜色
colors = sns.color_palette("Set2", n_colors=len(sorted_importance_df.columns))

# 创建图形和坐标轴对象，设置图形大小为12x6英寸，分辨率为1200 DPI
fig, ax = plt.subplots(figsize=(12, 6), dpi=1200)

# 初始化一个数组，用于记录每个条形图的底部位置，初始为0
bottom = np.zeros(len(elements))

# 遍历每个类别并绘制水平条形图
for i, column in enumerate(sorted_importance_df.columns):
    ax.barh(
        sorted_importance_df.index,     # y轴的特征名称
        sorted_importance_df[column],  # 当前类别的SHAP值
        left=bottom,                   # 设置条形图的起始位置
        color=colors[i],               # 使用调色板中的颜色
        label=column                   # 为图例添加类别名称
    )
    # 更新底部位置，以便下一个条形图能够正确堆叠
    bottom += sorted_importance_df[column]

# 设置x轴标签和标题
ax.set_xlabel('mean(SHAP value|)(average impact on model output magnitude)', fontsize=12)
ax.set_ylabel('Features', fontsize=12)
ax.set_title('Feature Importance by Class', fontsize=15)
# 设置y轴刻度和标签
ax.set_yticks(np.arange(len(elements)))
ax.set_yticklabels(elements, fontsize=10)
# 在条形图的末尾添加文本标签
for i, el in enumerate(elements):
    ax.text(bottom[i], i, ' ' + str(el), va='center', fontsize=9)
# 添加图例，并设置图例的字体大小和标题
ax.legend(title='Class', fontsize=10, title_fontsize=12)
# 禁用y轴的刻度和标签
ax.set_yticks([])  # 移除y轴刻度
ax.set_yticklabels([])  # 移除y轴刻度标签
ax.set_ylabel('')  # 移除y轴标签
# 移除顶部和右侧的边框，以获得更清晰的图形
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
plt.savefig('average impact on model output magnitude.pdf', format='pdf', bbox_inches='tight')
plt.show()
#####ICE
import matplotlib.pyplot as plt
from sklearn.inspection import PartialDependenceDisplay

# 获取数据集的所有特征名称
features = X.columns

# 计算需要的子图布局行数和列数
n_features = len(features)
n_cols = 6  # 固定列数
n_rows = (n_features // n_cols) + (1 if n_features % n_cols != 0 else 0)

# 创建一个适应特征数量的子图布局
fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, n_rows * 4), dpi=1200)
axes = axes.ravel()  # 将子图矩阵展平，方便逐个操作

# 针对类别0绘制每个特征的ICE图
for i, feature in enumerate(features):
    try:
        PartialDependenceDisplay.from_estimator(
            best_model, 
            X, 
            [feature], 
            kind='individual', 
            target=0, 
            ax=axes[i]  # 将图绘制到相应的子图中
        )
        axes[i].set_title(f'ICE for {feature}', fontsize=10)
    except Exception as e:
        print(f"Error plotting feature {feature}: {e}")
        axes[i].text(0.5, 0.5, 'Error', fontsize=15, ha='center')
        axes[i].set_title(f'Error for {feature}', fontsize=10)

# 调整子图之间的间距，特别是上下两排的间距
plt.subplots_adjust(hspace=0.5)  # 调整上下排之间的间距

# 自动调整布局
plt.tight_layout()

# 保存图像
plt.savefig('ICE_plots_0.pdf', format='pdf', bbox_inches='tight', dpi=1200)
plt.show()
